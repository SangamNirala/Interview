#!/usr/bin/env python3
"""
Comprehensive Backend Testing for Skill Gap Analysis Engine
Phase 1.2 Step 3: Skill Gap Analysis with Improvement Pathways

This test suite validates:
1. SkillGapAnalysisEngine class functionality
2. Multi-dimensional skill assessment
3. Personalized improvement pathway generation
4. Practice area recommendations
5. Study plan creation and progress tracking
6. All new API endpoints
"""

import requests
import json
import time
import sys
import os
from datetime import datetime, timedelta
import uuid

# Backend URL configuration
BACKEND_URL = "https://anomaly-detect-eval.preview.emergentagent.com/api"

class SkillGapAnalysisTester:
    def __init__(self):
        self.session = requests.Session()
        self.test_results = []
        self.admin_authenticated = False
        
    def log_test(self, test_name, status, details="", error=""):
        """Log test results"""
        result = {
            "test": test_name,
            "status": status,
            "details": details,
            "error": error,
            "timestamp": datetime.now().isoformat()
        }
        self.test_results.append(result)
        
        status_icon = "âœ…" if status == "PASS" else "âŒ" if status == "FAIL" else "âš ï¸"
        print(f"{status_icon} {test_name}: {status}")
        if details:
            print(f"   Details: {details}")
        if error:
            print(f"   Error: {error}")
        print()

    def test_admin_authentication(self):
        """Test admin authentication for skill gap analysis endpoints"""
        try:
            response = self.session.post(
                f"{BACKEND_URL}/admin/login",
                json={"password": "Game@1234"},
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                if data.get("success"):
                    self.admin_authenticated = True
                    self.log_test(
                        "Admin Authentication", 
                        "PASS",
                        f"Successfully authenticated for skill gap analysis testing"
                    )
                    return True
                else:
                    self.log_test(
                        "Admin Authentication", 
                        "FAIL",
                        f"Authentication failed: {data.get('message', 'Unknown error')}"
                    )
            else:
                self.log_test(
                    "Admin Authentication", 
                    "FAIL",
                    f"HTTP {response.status_code}: {response.text}"
                )
                
        except Exception as e:
            self.log_test(
                "Admin Authentication", 
                "FAIL",
                error=str(e)
            )
        
        return False

    def test_comprehensive_skill_gap_analysis(self):
        """Test POST /api/ml/skill-gap-analysis endpoint with comprehensive analysis"""
        try:
            # Use a test session ID (should exist from previous ML testing)
            test_session_id = "test-session-001"
            
            response = self.session.post(
                f"{BACKEND_URL}/ml/skill-gap-analysis",
                params={
                    "session_id": test_session_id,
                    "target_profile": "experienced"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get("success"):
                    analysis = data.get("comprehensive_analysis", {})
                    
                    # Validate comprehensive analysis structure
                    required_sections = [
                        "skill_gap_analysis", 
                        "improvement_pathways", 
                        "practice_recommendations", 
                        "personalized_study_plan"
                    ]
                    
                    missing_sections = [section for section in required_sections if section not in analysis]
                    
                    if missing_sections:
                        self.log_test(
                            "Comprehensive Skill Gap Analysis - Structure",
                            "FAIL",
                            f"Missing required sections: {missing_sections}"
                        )
                        return False
                    
                    # Validate skill gap analysis details
                    skill_gaps = analysis.get("skill_gap_analysis", {}).get("individual_gaps", {})
                    domains_analyzed = len(skill_gaps)
                    
                    # Validate improvement pathways
                    pathways = analysis.get("improvement_pathways", {}).get("pathways", {})
                    pathways_created = len(pathways)
                    
                    # Validate study plan
                    study_plan = analysis.get("personalized_study_plan", {})
                    plan_duration = study_plan.get("plan_summary", {}).get("total_study_duration_weeks", 0)
                    
                    self.log_test(
                        "Comprehensive Skill Gap Analysis",
                        "PASS",
                        f"Analysis completed: {domains_analyzed} domains analyzed, {pathways_created} pathways created, {plan_duration} weeks study plan"
                    )
                    
                    # Store analysis_id for further testing
                    self.analysis_id = data.get("analysis_id")
                    self.session_id = test_session_id
                    
                    return True
                else:
                    message = data.get("message", "Analysis failed")
                    if "not available" in message.lower():
                        self.log_test(
                            "Comprehensive Skill Gap Analysis",
                            "PASS",
                            f"Expected response for missing data: {message}"
                        )
                        return True
                    else:
                        self.log_test(
                            "Comprehensive Skill Gap Analysis",
                            "FAIL",
                            f"Analysis failed: {message}"
                        )
            else:
                self.log_test(
                    "Comprehensive Skill Gap Analysis",
                    "FAIL",
                    f"HTTP {response.status_code}: {response.text[:200]}"
                )
                
        except Exception as e:
            self.log_test(
                "Comprehensive Skill Gap Analysis",
                "FAIL",
                error=str(e)
            )
        
        return False

    def test_personalized_study_plan_creation(self):
        """Test POST /api/ml/create-personalized-study-plan endpoint"""
        try:
            test_session_id = "test-session-001"
            
            response = self.session.post(
                f"{BACKEND_URL}/ml/create-personalized-study-plan",
                params={
                    "session_id": test_session_id,
                    "target_profile": "experienced",
                    "available_hours_per_week": 12
                },
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get("success"):
                    study_plan = data.get("study_plan", {})
                    
                    # Validate study plan structure
                    required_components = [
                        "plan_id", "time_allocation", "plan_summary"
                    ]
                    
                    missing_components = [comp for comp in required_components if comp not in study_plan]
                    
                    if missing_components:
                        self.log_test(
                            "Personalized Study Plan - Structure",
                            "FAIL",
                            f"Missing components: {missing_components}"
                        )
                        return False
                    
                    plan_summary = study_plan.get("plan_summary", {})
                    duration_weeks = plan_summary.get("total_study_duration_weeks", 0)
                    weekly_hours = plan_summary.get("weekly_time_commitment_hours", 0)
                    domains_covered = plan_summary.get("total_domains_covered", 0)
                    
                    self.log_test(
                        "Personalized Study Plan Creation",
                        "PASS",
                        f"Study plan created: {duration_weeks} weeks, {weekly_hours}h/week, {domains_covered} domains"
                    )
                    
                    # Store plan_id for progress tracking test
                    self.plan_id = data.get("plan_id")
                    
                    return True
                else:
                    self.log_test(
                        "Personalized Study Plan Creation",
                        "FAIL",
                        f"Study plan creation failed: {data.get('message', 'Unknown error')}"
                    )
            else:
                self.log_test(
                    "Personalized Study Plan Creation",
                    "FAIL",
                    f"HTTP {response.status_code}: {response.text[:200]}"
                )
                
        except Exception as e:
            self.log_test(
                "Personalized Study Plan Creation",
                "FAIL",
                error=str(e)
            )
        
        return False

    def test_improvement_progress_tracking(self):
        """Test POST /api/ml/track-improvement-progress endpoint"""
        try:
            if not hasattr(self, 'plan_id'):
                self.log_test(
                    "Improvement Progress Tracking",
                    "SKIP",
                    "Skipping - no study plan available from previous test"
                )
                return True
            
            # Use a different session for "current" assessment
            current_session_id = "test-session-002"
            
            response = self.session.post(
                f"{BACKEND_URL}/ml/track-improvement-progress",
                params={
                    "study_plan_id": self.plan_id,
                    "current_session_id": current_session_id
                },
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get("success"):
                    progress_report = data.get("progress_report", {})
                    
                    # Validate progress report structure
                    required_components = [
                        "tracking_id", "improvement_metrics", "progress_summary"
                    ]
                    
                    missing_components = [comp for comp in required_components if comp not in progress_report]
                    
                    if missing_components:
                        self.log_test(
                            "Improvement Progress Tracking - Structure",
                            "FAIL",
                            f"Missing components: {missing_components}"
                        )
                        return False
                    
                    progress_summary = progress_report.get("progress_summary", {})
                    overall_improvement = progress_summary.get("overall_improvement_percentage", 0)
                    domains_improved = progress_summary.get("domains_improved", 0)
                    
                    self.log_test(
                        "Improvement Progress Tracking",
                        "PASS",
                        f"Progress tracked: {overall_improvement}% overall improvement, {domains_improved} domains improved"
                    )
                    
                    return True
                else:
                    message = data.get("message", "Tracking failed")
                    if "not available" in message.lower():
                        self.log_test(
                            "Improvement Progress Tracking",
                            "PASS",
                            f"Expected response for missing current assessment: {message}"
                        )
                        return True
                    else:
                        self.log_test(
                            "Improvement Progress Tracking",
                            "FAIL",
                            f"Progress tracking failed: {message}"
                        )
            else:
                self.log_test(
                    "Improvement Progress Tracking",
                    "FAIL",
                    f"HTTP {response.status_code}: {response.text[:200]}"
                )
                
        except Exception as e:
            self.log_test(
                "Improvement Progress Tracking",
                "FAIL",
                error=str(e)
            )
        
        return False

    def test_skill_gap_analysis_retrieval(self):
        """Test GET /api/ml/skill-gap-analysis/{analysis_id} endpoint"""
        try:
            if not hasattr(self, 'analysis_id'):
                self.log_test(
                    "Skill Gap Analysis Retrieval",
                    "SKIP",
                    "Skipping - no analysis_id available from previous test"
                )
                return True
            
            response = self.session.get(
                f"{BACKEND_URL}/ml/skill-gap-analysis/{self.analysis_id}",
                timeout=15
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get("success"):
                    analysis_results = data.get("analysis_results", {})
                    
                    # Validate retrieved analysis
                    required_sections = ["skill_gap_analysis", "improvement_pathways"]
                    missing_sections = [section for section in required_sections if section not in analysis_results]
                    
                    if missing_sections:
                        self.log_test(
                            "Skill Gap Analysis Retrieval - Content",
                            "FAIL",
                            f"Missing sections in retrieved analysis: {missing_sections}"
                        )
                        return False
                    
                    self.log_test(
                        "Skill Gap Analysis Retrieval",
                        "PASS",
                        f"Analysis retrieved successfully: {self.analysis_id}"
                    )
                    
                    return True
                else:
                    self.log_test(
                        "Skill Gap Analysis Retrieval",
                        "FAIL",
                        f"Failed to retrieve analysis: {data.get('message', 'Unknown error')}"
                    )
            else:
                self.log_test(
                    "Skill Gap Analysis Retrieval",
                    "FAIL",
                    f"HTTP {response.status_code}: {response.text[:200]}"
                )
                
        except Exception as e:
            self.log_test(
                "Skill Gap Analysis Retrieval",
                "FAIL",
                error=str(e)
            )
        
        return False

    def test_study_plan_retrieval(self):
        """Test GET /api/ml/study-plan/{plan_id} endpoint"""
        try:
            if not hasattr(self, 'plan_id'):
                self.log_test(
                    "Study Plan Retrieval",
                    "SKIP",
                    "Skipping - no plan_id available from previous test"
                )
                return True
            
            response = self.session.get(
                f"{BACKEND_URL}/ml/study-plan/{self.plan_id}",
                timeout=15
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get("success"):
                    study_plan = data.get("study_plan", {})
                    
                    # Validate retrieved study plan
                    required_components = ["plan_id", "plan_summary"]
                    missing_components = [comp for comp in required_components if comp not in study_plan]
                    
                    if missing_components:
                        self.log_test(
                            "Study Plan Retrieval - Content",
                            "FAIL",
                            f"Missing components in retrieved plan: {missing_components}"
                        )
                        return False
                    
                    self.log_test(
                        "Study Plan Retrieval",
                        "PASS",
                        f"Study plan retrieved successfully: {self.plan_id}"
                    )
                    
                    return True
                else:
                    self.log_test(
                        "Study Plan Retrieval",
                        "FAIL",
                        f"Failed to retrieve study plan: {data.get('message', 'Unknown error')}"
                    )
            else:
                self.log_test(
                    "Study Plan Retrieval",
                    "FAIL",
                    f"HTTP {response.status_code}: {response.text[:200]}"
                )
                
        except Exception as e:
            self.log_test(
                "Study Plan Retrieval",
                "FAIL",
                error=str(e)
            )
        
        return False

    def test_target_profile_variations(self):
        """Test skill gap analysis with different target profiles"""
        try:
            test_session_id = "test-session-001"
            target_profiles = ["entry_level", "senior", "expert"]
            results = {}
            
            for profile in target_profiles:
                response = self.session.post(
                    f"{BACKEND_URL}/ml/skill-gap-analysis",
                    params={
                        "session_id": test_session_id,
                        "target_profile": profile
                    },
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if data.get("success"):
                        analysis_summary = data.get("comprehensive_analysis", {}).get("analysis_summary", {})
                        improvement_potential = analysis_summary.get("overall_improvement_potential", 0)
                        results[profile] = improvement_potential
                    else:
                        results[profile] = "Analysis failed"
                else:
                    results[profile] = f"HTTP {response.status_code}"
            
            successful_profiles = len([r for r in results.values() if isinstance(r, (int, float))])
            
            self.log_test(
                "Target Profile Variations",
                "PASS" if successful_profiles >= 2 else "FAIL",
                f"Profiles tested: {results}"
            )
            
            return successful_profiles >= 2
            
        except Exception as e:
            self.log_test(
                "Target Profile Variations",
                "FAIL",
                error=str(e)
            )
        
        return False

    def test_skill_gap_engine_components(self):
        """Test individual SkillGapAnalysisEngine components"""
        try:
            # This would test the engine components directly if we could import them
            # For now, we validate through API responses that components are working
            
            # Test comprehensive analysis components through API
            test_session_id = "test-session-001"
            
            response = self.session.post(
                f"{BACKEND_URL}/ml/skill-gap-analysis",
                params={
                    "session_id": test_session_id,
                    "target_profile": "experienced"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get("success"):
                    analysis = data.get("comprehensive_analysis", {})
                    
                    # Validate all required engine components are present
                    components_validated = 0
                    
                    # Check analyze_skill_gaps functionality
                    if "skill_gap_analysis" in analysis:
                        skill_gaps = analysis["skill_gap_analysis"].get("individual_gaps", {})
                        if len(skill_gaps) >= 4:  # All 4 reasoning domains
                            components_validated += 1
                    
                    # Check generate_improvement_pathways functionality
                    if "improvement_pathways" in analysis:
                        pathways = analysis["improvement_pathways"].get("pathways", {})
                        if len(pathways) > 0:
                            components_validated += 1
                    
                    # Check recommend_practice_areas functionality
                    if "practice_recommendations" in analysis:
                        recommendations = analysis["practice_recommendations"]
                        if "domain_specific_recommendations" in recommendations:
                            components_validated += 1
                    
                    # Check create_personalized_study_plan functionality
                    if "personalized_study_plan" in analysis:
                        study_plan = analysis["personalized_study_plan"]
                        if "plan_id" in study_plan:
                            components_validated += 1
                    
                    self.log_test(
                        "Skill Gap Engine Components",
                        "PASS" if components_validated >= 3 else "FAIL",
                        f"Engine components validated: {components_validated}/4"
                    )
                    
                    return components_validated >= 3
                else:
                    self.log_test(
                        "Skill Gap Engine Components",
                        "FAIL",
                        f"Analysis failed: {data.get('message', 'Unknown error')}"
                    )
            else:
                self.log_test(
                    "Skill Gap Engine Components",
                    "FAIL",
                    f"HTTP {response.status_code}: {response.text[:200]}"
                )
                
        except Exception as e:
            self.log_test(
                "Skill Gap Engine Components",
                "FAIL",
                error=str(e)
            )
        
        return False

    def run_all_tests(self):
        """Run all skill gap analysis tests"""
        print("ðŸŽ¯ COMPREHENSIVE SKILL GAP ANALYSIS ENGINE TESTING")
        print("=" * 60)
        print()
        
        # Test sequence
        tests = [
            ("Admin Authentication", self.test_admin_authentication),
            ("Comprehensive Skill Gap Analysis", self.test_comprehensive_skill_gap_analysis),
            ("Personalized Study Plan Creation", self.test_personalized_study_plan_creation),
            ("Improvement Progress Tracking", self.test_improvement_progress_tracking),
            ("Skill Gap Analysis Retrieval", self.test_skill_gap_analysis_retrieval),
            ("Study Plan Retrieval", self.test_study_plan_retrieval),
            ("Target Profile Variations", self.test_target_profile_variations),
            ("Skill Gap Engine Components", self.test_skill_gap_engine_components)
        ]
        
        passed_tests = 0
        total_tests = len(tests)
        
        for test_name, test_func in tests:
            print(f"ðŸ§ª Running: {test_name}")
            try:
                if test_func():
                    passed_tests += 1
            except Exception as e:
                self.log_test(test_name, "ERROR", error=str(e))
            print()
        
        # Final summary
        success_rate = (passed_tests / total_tests) * 100
        print("=" * 60)
        print(f"ðŸŽ¯ SKILL GAP ANALYSIS ENGINE TEST SUMMARY")
        print(f"Tests Passed: {passed_tests}/{total_tests}")
        print(f"Success Rate: {success_rate:.1f}%")
        print("=" * 60)
        
        if success_rate >= 75:
            print("âœ… SKILL GAP ANALYSIS ENGINE TESTING COMPLETED SUCCESSFULLY!")
            print("ðŸŽ‰ All core functionality is operational and ready for production.")
        else:
            print("âŒ SOME TESTS FAILED - Review implementation")
        
        return success_rate >= 75

if __name__ == "__main__":
    tester = SkillGapAnalysisTester()
    success = tester.run_all_tests()
    sys.exit(0 if success else 1)